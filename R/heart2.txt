####
###
###  Heart Data - Decision Tree (Classification)
###               with Bagging, Random Forest, and Boosting
###
###  ver 0.0.2
####################################################


###-------------------------------------------------------
###--- 0. Preliminary

# Using Heart2 from https://nmimoto.github.io/R/heart0.txt
library(tidyverse)
Heart <- read_csv(file="https://nmimoto.github.io/datasets/heart.csv")

# Rename medv column as resp.
Heart2 <- Heart %>%
    select(-"index")  %>%            # remove col named "index"
    rename(resp=AHD) %>%             # rename the column
    relocate(resp) %>%               # move "resp" to 1st column
    mutate(resp=as.factor(resp),     # Turn these columns to <factor> instead of <double>
           ChestPain=as.factor(ChestPain),
           Thal=as.factor(Thal),
           Sex=as.factor(Sex),
           Fbs=as.factor(Fbs),
           RestECG=as.factor(RestECG),
           ExAng=as.factor(ExAng))

print(Heart2, width=1000)
table(Heart2$resp)    # note that first level is "No"

#1  resp        <fct> Used to be "AHD".  Yes/No based on an angiographic test  Qualitative <-- Response
#2  Age         <dbl>
#3  Sex         <fct>
#4  ChestPain   <fct>
#5  RestBP      <dbl>
#6  Chol        <dbl>
#7  Fbs         <fct>
#8  RestECG     <fct>
#9  MaxHR       <dbl>
#10 ExAng       <fct>
#11 Oldpeak     <dbl>
#12 Slope       <dbl>
#13 Ca          <dbl>
#14 Thal        <fct> (Thalium stress test)   Qualitative

# Low p-value from Chi-sq test of association
#  3 4 8 10 11 12 13 14
#  "Sex" "ChestPain" "RestECG" "ExAng" "Oldpeak" "Slope" "Ca" "Thal"
# High p-value from Chi-sq test of association
#  7
#  "Fbs"

# need to remove rows with NA.
Orig <- Heart2

#- Check for N/A in data. Remove if there's any.
  summary(Orig)
  dim(Orig)
  sum(is.na(Orig))
  # If there is na in the data, run below
  Orig <- Orig %>% na.omit()
  dim(Orig)


###--------------------------------------------------------------------
###--- 2. Divide Dataset to Training and Testing and Set up k fold CV
Orig <- Orig                 # Entire Data set (have to be data.frame)
train.size <- 250            # num of rows for training set
test.size <-  47             # num of rows for testing set
resp.col.name <- "resp"      # name of response column
num.folds <- 5               # k for k-fold CV
my.seed <- 7211             # give a seed

    #---
    set.seed(my.seed)
    ix = sample(1:nrow(Orig))
    Orig2 = Orig[ix, ]
    Train.set  = Orig2[1:train.size, ]
    Train.resp = Orig2[1:train.size, resp.col.name]
    Test.set   = Orig2[(train.size+1):(train.size+test.size), ]
    Test.resp  = Orig2[(train.size+1):(train.size+test.size), resp.col.name]

    # K-fold Cross Validation
    library(cvTools)     # install.packages("cvTools")
    set.seed(my.seed)
    folds = cvFolds(  nrow(Train.set),  K=num.folds  )  # k-fold CV (random assignment)

    CV.train      = list(Train.set[ folds$which!=1, ])
    CV.train.resp = list(Train.resp[folds$which!=1,1])
    CV.valid      = list(Train.set[ folds$which==1, ])
    CV.valid.resp = list(Train.resp[folds$which==1,1])

    for (k in 2:num.folds) {
      CV.train[[k]]      = Train.set[ folds$which!=k, ]
      CV.train.resp[[k]] = Train.resp[folds$which!=k,1]
      CV.valid[[k]]      = Train.set[ folds$which==k, ]
      CV.valid.resp[[k]] = Train.resp[folds$which==k,1]
    }
# Output (all data.frame):
#   Train.set      /  Train.resp
#   Test.set       /  Test.resp
#   CV.train[[k]]  /  CV.train.resp[[k]]
#   CV.valid[[k]]  /  CV.valid.resp[[k]]





###-------------------------------------------------
###--- 3. Decision Tree (Grow and Prune using tree())

#--- Growing the tree with Train.set
library(tree)
tree1 = tree(resp~., Train.set)
summary(tree1)
tree1

plot(tree1)
text(tree1, pretty=0, cex=1)


#--- Pruning the tree
set.seed(my.seed)
cv.for.pruning = cv.tree(tree1, FUN=prune.misclass, K=5)   #5-fold CV
     #use FUN= prune.tree if you are doing regression tree
names(cv.for.pruning)

plot(cv.for.pruning$size, cv.for.pruning$dev, type="b")
plot(cv.for.pruning$k, cv.for.pruning$dev, type="b")
# dev is the Av. CV error rate
# k is the pruning parameter (alpha)
# size is the number of terminal nodes

cv.for.pruning

#- We conclude that it's better to purne at 7 nodes.
prune1 = prune.tree(tree1, best=7)  # specify 7-node tree
plot(prune1)
text(prune1, pretty=0, cex=1)


#- Pick a threshold and visualize fit
Chosen.model <- prune1   # results from CV tuning
threshold <- .5

    #------------------
    #- Training Confusion Matrix
    Train.prob0 = predict(Chosen.model, type="vector")
    Train.prob  = Train.prob0[,"Yes"]
    Train.pred = ifelse(Train.prob > threshold, "Yes", "No")  # Turn the fitted values to Up/Down using threshold of .5
    CM.train <- caret::confusionMatrix(factor(Train.pred), factor(as.matrix(Train.resp)), positive="Yes")
    CM.train

    #- Testing Confusion Matrix
    Test.prob0 = predict(Chosen.model, Test.set, type="vector")
    Test.prob = Test.prob0[,"Yes"]
    Test.pred = ifelse(Test.prob > threshold, "Yes", "No")
    CM.test <- caret::confusionMatrix(factor(Test.pred), factor(as.matrix(Test.resp)), positive="Yes")
    CM.test

    #- ROC curve and AUC
    library(pROC)
    # Training
    layout(matrix(1:2,1,2))
    pROC::plot.roc(factor(as.matrix(Train.resp)), as.vector(Train.prob), levels=c("No", "Yes"))
    # point corresponding to CM.train
    abline(h=CM.train[["byClass"]][["Sensitivity"]], v=CM.train[["byClass"]][["Specificity"]], col="red")
    auc.train = pROC::auc(factor(as.matrix(Train.resp)), as.vector(Train.prob), levels=c("No", "Yes"))
    text(.2, .2, paste("AUC=",round(auc.train, 3)))
    #- Testing
    pROC::plot.roc(factor(as.matrix(Test.resp)),
               as.vector(Test.prob), levels=c("No", "Yes"))
    # point corresponding to CM.train
    abline(h=CM.test[["byClass"]][["Sensitivity"]], v=CM.test[["byClass"]][["Specificity"]], col="red")
    auc.test = pROC::auc(factor(as.matrix(Test.resp)), as.vector(Test.prob), levels=c("No", "Yes"))
    text(.2, .2, paste("AUC=",round(auc.test, 3)))
    layout(1)

    c(auc.train, auc.test)








(Under Construction Below)



###-------------------------------------------------
###--- 3. Bagging
library(randomForest)
set.seed(my.seed)
treeRF01 = randomForest(resp~., data=Train.set, mtry=13, ntree=500, importance=TRUE)
treeRF01

importance(treeRF01)
varImpPlot(treeRF01)

Test.pred = predict(treeRF01, newdata=Test.set)


#- Pick a threshold and visualize fit
Chosen.model <- prune1   # results from CV tuning
threshold <- .5

    #------------------
    #- Training Confusion Matrix
    Train.prob0 = predict(Chosen.model, type="vector")
    Train.prob  = Train.prob0[,"Yes"]
    Train.pred = ifelse(Train.prob > threshold, "Yes", "No")  # Turn the fitted values to Up/Down using threshold of .5
    CM.train <- caret::confusionMatrix(factor(Train.pred), factor(as.matrix(Train.resp)), positive="Yes")
    CM.train

    #- Testing Confusion Matrix
    Test.prob0 = predict(Chosen.model, Test.set, type="vector")
    Test.prob = Test.prob0[,"Yes"]
    Test.pred = ifelse(Test.prob > threshold, "Yes", "No")
    CM.test <- caret::confusionMatrix(factor(Test.pred), factor(as.matrix(Test.resp)), positive="Yes")
    CM.test

    #- ROC curve and AUC
    library(pROC)
    # Training
    layout(matrix(1:2,1,2))
    pROC::plot.roc(factor(as.matrix(Train.resp)), as.vector(Train.prob), levels=c("No", "Yes"))
    # point corresponding to CM.train
    abline(h=CM.train[["byClass"]][["Sensitivity"]], v=CM.train[["byClass"]][["Specificity"]], col="red")
    auc.train = pROC::auc(factor(as.matrix(Train.resp)), as.vector(Train.prob), levels=c("No", "Yes"))
    text(.2, .2, paste("AUC=",round(auc.train, 3)))
    #- Testing
    pROC::plot.roc(factor(as.matrix(Test.resp)),
               as.vector(Test.prob), levels=c("No", "Yes"))
    # point corresponding to CM.train
    abline(h=CM.test[["byClass"]][["Sensitivity"]], v=CM.test[["byClass"]][["Specificity"]], col="red")
    auc.test = pROC::auc(factor(as.matrix(Test.resp)), as.vector(Test.prob), levels=c("No", "Yes"))
    text(.2, .2, paste("AUC=",round(auc.test, 3)))
    layout(1)

    c(auc.train, auc.test)












###-------------------------------------------------
###--- 3. Radnom Forest

###--- change mtry to 6
library(randomForest)
set.seed(my.seed)
treeRF03 = randomForest(medv~., data=Train.set, mtry=6, ntree=500, importance=TRUE)
treeRF03

importance (treeRF03)
varImpPlot (treeRF03)

Test.pred = predict(treeRF03, newdata=Test.set)









###-------------------------------------------------
###--- 4. Boosting
set.seed(my.seed)
treeBT01 = gbm::gbm(medv~., data=Train.set, distribution="gaussian", n.trees=5000,
             interaction.depth=4)
summary(treeBT01)

plot(treeBT01, i="rm")
plot(treeBT01, i="lstat")

Test.pred=predict(treeBT01, newdata=Test.set, n.trees=5000)
















###-----------------------------------------------------------
###--- Threshold Picker

#cost.list = c(0,0,3,1)/4           # order of (TP, TN, FP, FN)
cost.list = c(0,0,2,1)/3           # order of (TP, TN, FP, FN)
#cost.list = c(0,0,1,1)/2           # order of (TP, TN, FP, FN)
#cost.list = c(0,0,1,2)/3           # order of (TP, TN, FP, FN)
#cost.list = c(0,0,1,3)/4           # order of (TP, TN, FP, FN)


threshold.list = seq(0.01,.99,.01)    # grid for threshold
cost=0
library(caret)      # for confusionMatrix
for (i in 1:length(threshold.list)){

  threshold = threshold.list[i]

  #- Check the training set accuracy
  Test.pred  = ifelse(Test.prob  > threshold, "Yes", "No")
  CM.test  <- confusionMatrix(factor(Test.pred),
                              factor(as.matrix(Test.resp)),
                              positive="Yes")
  TP = CM.test$table[2,2]   # True  Pos
  TN = CM.test$table[1,1]   # True  Neg
  FP = CM.test$table[2,1]   # False Pos
  FN = CM.test$table[1,2]   # False Neg

  cost[i] = sum(c(TP, TN, FP, FN) * cost.list)
}
plot(threshold.list, cost, xlab="threshold")

cost.list
which.min(cost)
min(cost)
threshold.list[which.min(cost)]
