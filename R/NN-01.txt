###
###
###  Newral Network Demo
###
###
####################################################
## From this blog:
##  https://selbydavid.com/2018/01/09/neural-network/


activation <- function(x) 1 / (1 + exp(-x))  # sigmoid

feedforward <- function(x, w1, w2) {
  z1 <- cbind(1, x) %*% w1
  h  <- activation(z1)
  z2 <- cbind(1, h) %*% w2
  list(output=activation(z2), h=h)
}

backpropagate <- function(x, y, y_hat, w1, w2, h, learn_rate) {
  dw2 <- t(cbind(1, h)) %*% (y_hat-y)
  dh  <- (y_hat - y) %*% t(w2[-1, , drop = FALSE])
  dw1 <- t(cbind(1, x)) %*% (h * (1-h) * dh)

  w1 <- w1 - learn_rate*dw1
  w2 <- w2 - learn_rate*dw2

  list(w1=w1, w2=w2)
}

train <- function(x, y, hidden = 5, learn_rate = 1e-2, iterations = 1e4) {
  d <-  ncol(x) + 1
  w1 <- matrix(rnorm(d * hidden), d, hidden)
  w2 <- as.matrix(rnorm(hidden + 1))
  for (i in 1:iterations) {
    ff <- feedforward(x, w1, w2)
    bp <- backpropagate(x, y,
                        y_hat=ff$output,
                        w1, w2,
                        h=ff$h,
                        learn_rate=learn_rate)
    w1 <- bp$w1; w2 <- bp$w2
  }
  list(output = ff$output, w1 = w1, w2 = w2)
}

##--- Simulate Spiral Data Set
two_spirals <- function(N, radians=3*pi, theta0=pi/2, labels=0:1) {
  N1 <- floor(N/2)
  N2 <- N - N1

  theta   <- theta0 + runif(N1) * radians
  spiral1 <- cbind(-theta*cos(theta)+runif(N1),  theta*sin(theta)+runif(N1))
  spiral2 <- cbind( theta*cos(theta)+runif(N2), -theta*sin(theta)+runif(N2))
  points  <- rbind(spiral1, spiral2)
  classes <- c(rep(0, N1), rep(1, N2))

  data.frame(x1=points[, 1], x2=points[, 2],
             resp=factor(classes, labels = labels))
}







##-------------------------------------------------------------------
##--- Generate Spiral Data


# set.seed(122) # <- looks good
# set.seed(42)
library(tidyverse)
set.seed(45)
Orig <- as_tibble(two_spirals(200, labels = c('No', 'Yes')))

Orig2 <- Orig %>% mutate(resp=as.numeric(resp=="Yes"))
Orig2


library(ggplot2)
ggplot(Orig, aes(x1, x2, colour=resp)) + geom_point()


##--- Training NN
x <- as.matrix(Orig2[, c('x1', 'x2')])
y <- Orig2$resp
nnet0 <- train(x, y, hidden=1,  iterations=1e5)
nnet1 <- train(x, y, hidden=10, iterations=1e5)
nnet2 <- train(x, y, hidden=20, iterations=1e5)
nnet3 <- train(x, y, hidden=30, iterations=1e5)
nnet4 <- train(x, y, hidden=40, iterations=1e5)


##--- Visualize the result

nnet <- nnet4

    # portion of correctly respified
    mean((nnet$output>.5)==y)

    # Visualize Fit
    grid <- expand.grid(x1=seq(min(Orig$x1)-1, max(Orig$x1)+1, by=.25),
                    x2=seq(min(Orig$x2)-1, max(Orig$x2)+1, by=.25))
    ff_grid <- feedforward(x=data.matrix(grid[, c('x1', 'x2')]),
                       w1=nnet$w1,
                       w2=nnet$w2)
    grid$resp <- factor((ff_grid$output>.5)*1, labels=levels(Orig$resp))

    ggplot(Orig) + aes(x1, x2, colour=resp) +
             geom_point(data=grid, size=.5) +
             geom_point()



###------------------------------------------------
##--- Try to do the same with neuralnet
library(neuralnet)
sigmoid <- function(x) 1 / (1 + exp(-x))

# working
NN.fit0 <- neuralnet(resp~., Orig2, learningrate=1e-2, act.fct=sigmoid, hidden=1,  linear.output=TRUE, likelihood=TRUE)
NN.fit2 <- neuralnet(resp~., Orig2, learningrate=1e-2, act.fct=sigmoid, hidden=20, linear.output=TRUE)
NN.fit3 <- neuralnet(resp~., Orig2, learningrate=1e-2, act.fct=sigmoid, hidden=30, linear.output=TRUE)

# not working
NN.fit1 <- neuralnet(resp~., Orig2, learningrate=1e-4, act.fct=sigmoid, hidden=10, linear.output=TRUE)
NN.fit4 <- neuralnet(resp~., Orig2, learningrate=1e-4, act.fct=sigmoid, hidden=40, linear.output=TRUE)
NN.fit5 <- neuralnet(resp~., Orig2, learningrate=1e-4, act.fct=sigmoid, hidden=50, linear.output=TRUE)

# Predict for TEST set
compute(NN.fit,  Orig)

mean((NN$net.result>.5)==Orig2$resp)

plot(NN.fit3)
